{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 리스트 만드는 정리 함수 정의\n",
    "\n",
    "def filtering_data(input_data):\n",
    "    col = input_data.columns[0]\n",
    "    input_data1 = input_data[col]\n",
    "    \n",
    "    input_value = input_data1[13:]\n",
    "    input_value_list = input_value.values\n",
    "\n",
    "    input_value_list1 = []\n",
    "\n",
    "    for i in range(0, len(input_value_list)):\n",
    "        input_value_list1.append(input_value_list[i])\n",
    "            \n",
    "    return input_value_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일 읽어온 후 새롭게 정의\n",
    "\n",
    "sw_1999 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_1999.csv', engine='python')\n",
    "sw_2000 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2000.csv', engine='python')\n",
    "sw_2001 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2001.csv', engine='python')\n",
    "sw_2002 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2002.csv', engine='python')\n",
    "sw_2003 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2003.csv', engine='python')\n",
    "sw_2004 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2004.csv', engine='python')\n",
    "sw_2005 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2005.csv', engine='python')\n",
    "sw_2006 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2006.csv', engine='python')\n",
    "sw_2007 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2007.csv', engine='python')\n",
    "sw_2008 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2008.csv', engine='python')\n",
    "sw_2009 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2009.csv', engine='python')\n",
    "sw_2010 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2010.csv', engine='python')\n",
    "sw_2011 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2011.csv', engine='python')\n",
    "sw_2012 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2012.csv', engine='python')\n",
    "sw_2013 = pd.read_csv('C:\\Projects\\keras_talk\\comp_ace\\\\ace_2013.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어온 csv파일을 정리 함수에 적용하여 새롭게 정의\n",
    "\n",
    "sw_1999_filter = filtering_data(sw_1999)\n",
    "sw_2000_filter = filtering_data(sw_2000)\n",
    "sw_2001_filter = filtering_data(sw_2001)\n",
    "sw_2002_filter = filtering_data(sw_2002)\n",
    "sw_2003_filter = filtering_data(sw_2003)\n",
    "sw_2004_filter = filtering_data(sw_2004)\n",
    "sw_2005_filter = filtering_data(sw_2005)\n",
    "sw_2006_filter = filtering_data(sw_2006)\n",
    "sw_2007_filter = filtering_data(sw_2007)\n",
    "sw_2008_filter = filtering_data(sw_2008)\n",
    "sw_2009_filter = filtering_data(sw_2009)\n",
    "sw_2010_filter = filtering_data(sw_2010)\n",
    "sw_2011_filter = filtering_data(sw_2011)\n",
    "sw_2012_filter = filtering_data(sw_2012)\n",
    "sw_2013_filter = filtering_data(sw_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1999   1  0  0      7.149  9.2352e+04    406.00   -2.174   -2.598    5.550    6.630', '1999   1  0  1      5.998  8.5859e+04    419.12   -1.245   -0.140    6.558    6.796', '1999   1  0  2      6.211  8.1547e+04    411.99   -2.003   -1.198    6.306    6.802']\n"
     ]
    }
   ],
   "source": [
    "print(sw_1999_filter[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새롭게 정의된 데이터 안에서 공백 기준으로 원소 split해서 \n",
    "# 리스트 안의 새로운 리스트들 만드는 함수 정의\n",
    "\n",
    "def split_data(input_data):\n",
    "    input_value = []\n",
    "    for i in range(0, len(input_data)):\n",
    "        spl = input_data[i].split()\n",
    "        input_value.append(spl)\n",
    "    return input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백 기준으로 split된 원소들의 리스트를 만드는 함수를 리스트에 적용\n",
    "\n",
    "input_value_1999 = split_data(sw_1999_filter)\n",
    "input_value_2000 = split_data(sw_2000_filter)\n",
    "input_value_2001 = split_data(sw_2001_filter)\n",
    "input_value_2002 = split_data(sw_2002_filter)\n",
    "input_value_2003 = split_data(sw_2003_filter)\n",
    "input_value_2004 = split_data(sw_2004_filter)\n",
    "input_value_2005 = split_data(sw_2005_filter)\n",
    "input_value_2006 = split_data(sw_2006_filter)\n",
    "input_value_2007 = split_data(sw_2007_filter)\n",
    "input_value_2008 = split_data(sw_2008_filter)\n",
    "input_value_2009 = split_data(sw_2009_filter)\n",
    "input_value_2010 = split_data(sw_2010_filter)\n",
    "input_value_2011 = split_data(sw_2011_filter)\n",
    "input_value_2012 = split_data(sw_2012_filter)\n",
    "input_value_2013 = split_data(sw_2013_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1999, 1, 0, 0, 7.149, 92352.0, 406.0, -2.174, -2.598, 5.55, 6.63], [1999, 1, 0, 1, 5.998, 85859.0, 419.12, -1.245, -0.14, 6.558, 6.796], [1999, 1, 0, 2, 6.211, 81547.0, 411.99, -2.003, -1.198, 6.306, 6.802]]\n"
     ]
    }
   ],
   "source": [
    "print(input_value_1999[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '2', '3', '4'], ['5', '6'], ['7', '8', '9']]\n"
     ]
    }
   ],
   "source": [
    "# list에서의 split 실험\n",
    "\n",
    "list1=['1 2 3 4','5 6','7 8 9']\n",
    "input_value=[]\n",
    "for i in range (0,3):\n",
    "    spl = list1[i].split()\n",
    "    input_value.append(spl)\n",
    "print(input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자형을 숫자로 바꾸는, 데이터 프레임 만들기\n",
    "\n",
    "def mk_DF(input_value): # input_value는 split 처리된 값 넣기\n",
    "    for j in range(len(input_value)):\n",
    "        for i in range(11):\n",
    "            if i < 4 :\n",
    "                input_value[j][i] = int(input_value[j][i])\n",
    "            else :\n",
    "                input_value[j][i] = float(input_value[j][i])\n",
    "                \n",
    "    arr_year=[]\n",
    "    arr_doy=[]\n",
    "    arr_hr=[]\n",
    "    arr_min=[]\n",
    "    arr_Np=[]\n",
    "    arr_Tp=[]\n",
    "    arr_Vp=[]\n",
    "    arr_Bgsm_x=[]\n",
    "    arr_Bgsm_y=[]\n",
    "    arr_Bgsm_z=[]\n",
    "    arr_Bt=[]\n",
    "\n",
    "    for i in range(len(input_value)):\n",
    "        arr_year.append(input_value[i][0])\n",
    "        arr_doy.append(input_value[i][1])\n",
    "        arr_hr.append(input_value[i][2])\n",
    "        arr_min.append(input_value[i][3])\n",
    "        arr_Np.append(input_value[i][4])\n",
    "        arr_Tp.append(input_value[i][5])\n",
    "        arr_Vp.append(input_value[i][6])\n",
    "        arr_Bgsm_x.append(input_value[i][7])\n",
    "        arr_Bgsm_y.append(input_value[i][8])\n",
    "        arr_Bgsm_z.append(input_value[i][9])\n",
    "        arr_Bt.append(input_value[i][10])\n",
    "        \n",
    "    raw_data = OrderedDict() # 순서대로 딕셔너리 만들기\n",
    "    \n",
    "    raw_data['year'] = arr_year\n",
    "    raw_data['doy'] = arr_doy\n",
    "    raw_data['hr'] = arr_hr\n",
    "    raw_data['min'] = arr_min\n",
    "    raw_data['Np'] = arr_Np\n",
    "    raw_data['Tp'] = arr_Tp\n",
    "    raw_data['Vp'] = arr_Vp\n",
    "    raw_data['Bgsm_x'] = arr_Bgsm_x\n",
    "    raw_data['Bgsm_y'] = arr_Bgsm_y\n",
    "    raw_data['Bgsm_z'] = arr_Bgsm_z\n",
    "    raw_data['Bt'] = arr_Bt\n",
    "    \n",
    "    data = pd.DataFrame(raw_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임으로 바꾸는 함수를 적용시켜서 새로운 데이터 만들기\n",
    "\n",
    "data_1999=mk_DF(input_value_1999)\n",
    "data_2000=mk_DF(input_value_2000)\n",
    "data_2001=mk_DF(input_value_2001)\n",
    "data_2002=mk_DF(input_value_2002)\n",
    "data_2003=mk_DF(input_value_2003)\n",
    "data_2004=mk_DF(input_value_2004)\n",
    "data_2005=mk_DF(input_value_2005)\n",
    "data_2006=mk_DF(input_value_2006)\n",
    "data_2007=mk_DF(input_value_2007)\n",
    "data_2008=mk_DF(input_value_2008)\n",
    "data_2009=mk_DF(input_value_2009)\n",
    "data_2010=mk_DF(input_value_2010)\n",
    "data_2011=mk_DF(input_value_2011)\n",
    "data_2012=mk_DF(input_value_2012)\n",
    "data_2013=mk_DF(input_value_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  doy  hr  min        Np        Tp       Vp  Bgsm_x  Bgsm_y  \\\n",
      "0       1999    1   0    0     7.149   92352.0   406.00  -2.174  -2.598   \n",
      "1       1999    1   0    1     5.998   85859.0   419.12  -1.245  -0.140   \n",
      "2       1999    1   0    2     6.211   81547.0   411.99  -2.003  -1.198   \n",
      "3       1999    1   0    3     6.680   72308.0   405.25  -3.093  -2.483   \n",
      "4       1999    1   0    4 -9999.900   -9999.9 -9999.90  -3.009  -1.500   \n",
      "...      ...  ...  ..  ...       ...       ...      ...     ...     ...   \n",
      "492746  1999  365  23   55     3.365  363370.0   679.56  -4.768  -2.678   \n",
      "492747  1999  365  23   56     3.629  338670.0   690.92  -3.590  -4.599   \n",
      "492748  1999  365  23   57     3.665  311130.0   672.87  -5.656   1.779   \n",
      "492749  1999  365  23   58     3.135  247120.0   680.03  -5.747   3.764   \n",
      "492750  1999  365  23   59 -9999.900   -9999.9 -9999.90  -4.363  -1.571   \n",
      "\n",
      "        Bgsm_z     Bt  \n",
      "0        5.550  6.630  \n",
      "1        6.558  6.796  \n",
      "2        6.306  6.802  \n",
      "3        5.545  6.854  \n",
      "4        5.908  6.842  \n",
      "...        ...    ...  \n",
      "492746   2.451  6.173  \n",
      "492747   2.820  6.677  \n",
      "492748   4.514  7.673  \n",
      "492749   4.632  8.330  \n",
      "492750   4.486  7.700  \n",
      "\n",
      "[492751 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성된 데이터를 csv파일로 출력 \n",
    "# (이렇게 만든 데이터들의 미싱데이터를 엑셀 상에서 공백으로 모두 교체)\n",
    "\n",
    "data_1999.to_csv('./ace_1999.csv', index=False)\n",
    "data_2000.to_csv('./ace_2000.csv', index=False)\n",
    "data_2001.to_csv('./ace_2001.csv', index=False)\n",
    "data_2002.to_csv('./ace_2002.csv', index=False)\n",
    "data_2003.to_csv('./ace_2003.csv', index=False)\n",
    "data_2004.to_csv('./ace_2004.csv', index=False)\n",
    "data_2005.to_csv('./ace_2005.csv', index=False)\n",
    "data_2006.to_csv('./ace_2006.csv', index=False)\n",
    "data_2007.to_csv('./ace_2007.csv', index=False)\n",
    "data_2008.to_csv('./ace_2008.csv', index=False)\n",
    "data_2009.to_csv('./ace_2009.csv', index=False)\n",
    "data_2010.to_csv('./ace_2010.csv', index=False)\n",
    "data_2011.to_csv('./ace_2011.csv', index=False)\n",
    "data_2012.to_csv('./ace_2012.csv', index=False)\n",
    "data_2013.to_csv('./ace_2013.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15분 간격으로 데이터들의 평균을 만들어서 리스트에 저장하는 함수를 모듈로 저장 후 import\n",
    "\n",
    "import AverageFunction4 as af\n",
    "import AverageFunction6 as af2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# af함수를 거친 값을 다른 변수에 저장시키는 함수\n",
    "\n",
    "def avg(data):\n",
    "    avg_Np = af.Np_average(data)\n",
    "    avg_Tp = af.Tp_average(data)\n",
    "    avg_Vp = af.Vp_average(data)\n",
    "    avg_Bgsm_x = af.B_gsm_x_average(data)\n",
    "    avg_Bgsm_y = af.B_gsm_y_average(data)\n",
    "    avg_Bgsm_z = af.B_gsm_z_average(data)\n",
    "    avg_Bt = af.Bt_average(data)\n",
    "    \n",
    "    return avg_Np, avg_Tp, avg_Vp, avg_Bgsm_x, avg_Bgsm_y, avg_Bgsm_z, avg_Bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# af함수를 거친 값을 다른 변수에 저장시키는 함수 - 윤년 전용\n",
    "\n",
    "def avg2(data):\n",
    "    avg_Np = af2.Np_average(data)\n",
    "    avg_Tp = af2.Tp_average(data)\n",
    "    avg_Vp = af2.Vp_average(data)\n",
    "    avg_Bgsm_x = af2.B_gsm_x_average(data)\n",
    "    avg_Bgsm_y = af2.B_gsm_y_average(data)\n",
    "    avg_Bgsm_z = af2.B_gsm_z_average(data)\n",
    "    avg_Bt = af2.Bt_average(data)\n",
    "    \n",
    "    return avg_Np, avg_Tp, avg_Vp, avg_Bgsm_x, avg_Bgsm_y, avg_Bgsm_z, avg_Bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든, 깔끔하게 정리된 데이터 파일 및 문제 데이터 파일 (미싱데이터가 공백으로 대체됨) 불러오기\n",
    "\n",
    "path = 'C:\\Projects\\keras_talk\\comp_ace_an\\\\'\n",
    "\n",
    "data_1999 = pd.read_csv(path + 'ace_1999_an.csv', engine='python')\n",
    "data_2000 = pd.read_csv(path + 'ace_2000_an.csv', engine='python')\n",
    "data_2001 = pd.read_csv(path + 'ace_2001_an.csv', engine='python')\n",
    "data_2002 = pd.read_csv(path + 'ace_2002_an.csv', engine='python')\n",
    "data_2003 = pd.read_csv(path + 'ace_2003_an.csv', engine='python')\n",
    "data_2004 = pd.read_csv(path + 'ace_2004_an.csv', engine='python')\n",
    "data_2005 = pd.read_csv(path + 'ace_2005_an.csv', engine='python')\n",
    "data_2006 = pd.read_csv(path + 'ace_2006_an.csv', engine='python')\n",
    "data_2007 = pd.read_csv(path + 'ace_2007_an.csv', engine='python')\n",
    "data_2008 = pd.read_csv(path + 'ace_2008_an.csv', engine='python')\n",
    "data_2009 = pd.read_csv(path + 'ace_2009_an.csv', engine='python')\n",
    "data_2010 = pd.read_csv(path + 'ace_2010_an.csv', engine='python')\n",
    "data_2011 = pd.read_csv(path + 'ace_2011_an.csv', engine='python')\n",
    "data_2012 = pd.read_csv(path + 'ace_2012_an.csv', engine='python')\n",
    "data_2013 = pd.read_csv(path + 'ace_2013_an.csv', engine='python')\n",
    "\n",
    "data_prob = pd.read_csv(path + 'problem_data_an.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\keras_talk\\AverageFunction4.py:34: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Np_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:39: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Np_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:24: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Np_data_00)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:29: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Np_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:78: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Tp_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:83: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Tp_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:68: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Tp_data_00)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:73: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Tp_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:116: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Vp_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:121: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Vp_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:126: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Vp_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction4.py:111: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Vp_data_00)\n"
     ]
    }
   ],
   "source": [
    "# 위에서 만든, 깔끔하게 정리된 데이터 파일 및 문제 데이터 파일 불러오기 (1999(보통)만)\n",
    "\n",
    "path = 'C:\\Projects\\keras_talk\\comp_ace_an\\\\'\n",
    "\n",
    "data_1999 = pd.read_csv(path + 'ace_1999_an.csv', engine='python')\n",
    "\n",
    "avg_Np_1999, avg_Tp_1999, avg_Vp_1999, avg_Bgsm_x_1999, avg_Bgsm_y_1999, avg_Bgsm_z_1999, avg_Bt_1999 = avg(data_1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\keras_talk\\AverageFunction6.py:24: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Np_data_00)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:29: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Np_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:34: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Np_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:39: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Np_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:68: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Tp_data_00)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:73: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Tp_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:78: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Tp_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:83: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Tp_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:116: RuntimeWarning: Mean of empty slice\n",
      "  avr_15 = np.nanmean(Vp_data_15)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:121: RuntimeWarning: Mean of empty slice\n",
      "  avr_30 = np.nanmean(Vp_data_30)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:126: RuntimeWarning: Mean of empty slice\n",
      "  avr_45 = np.nanmean(Vp_data_45)\n",
      "c:\\projects\\keras_talk\\AverageFunction6.py:111: RuntimeWarning: Mean of empty slice\n",
      "  avr_00 = np.nanmean(Vp_data_00)\n"
     ]
    }
   ],
   "source": [
    "# 위에서 만든, 깔끔하게 정리된 데이터 파일 및 문제 데이터 파일 불러오기 (2000(윤년)만)\n",
    "\n",
    "path = 'C:\\Projects\\keras_talk\\comp_ace_an\\\\'\n",
    "\n",
    "data_2000 = pd.read_csv(path + 'ace_2000_an.csv', engine='python')\n",
    "\n",
    "avg_Np_2000, avg_Tp_2000, avg_Vp_2000, avg_Bgsm_x_2000, avg_Bgsm_y_2000, avg_Bgsm_z_2000, avg_Bt_2000 = avg2(data_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg 함수를 적용시켜서 각 년도의 각 변수들을 정의 (돌리는 데 시간이 오래 걸리지만 위의 테스트로 되는 것 확인)\n",
    "\n",
    "avg_Np_1999, avg_Tp_1999, avg_Vp_1999, avg_Bgsm_x_1999, avg_Bgsm_y_1999, avg_Bgsm_z_1999, avg_Bt_1999 = avg(data_1999)\n",
    "avg_Np_2000, avg_Tp_2000, avg_Vp_2000, avg_Bgsm_x_2000, avg_Bgsm_y_2000, avg_Bgsm_z_2000, avg_Bt_2000 = avg2(data_2000)\n",
    "avg_Np_2001, avg_Tp_2001, avg_Vp_2001, avg_Bgsm_x_2001, avg_Bgsm_y_2001, avg_Bgsm_z_2001, avg_Bt_2001 = avg(data_2001)\n",
    "avg_Np_2002, avg_Tp_2002, avg_Vp_2002, avg_Bgsm_x_2002, avg_Bgsm_y_2002, avg_Bgsm_z_2002, avg_Bt_2002 = avg(data_2002)\n",
    "avg_Np_2003, avg_Tp_2003, avg_Vp_2003, avg_Bgsm_x_2003, avg_Bgsm_y_2003, avg_Bgsm_z_2003, avg_Bt_2003 = avg(data_2003)\n",
    "avg_Np_2004, avg_Tp_2004, avg_Vp_2004, avg_Bgsm_x_2004, avg_Bgsm_y_2004, avg_Bgsm_z_2004, avg_Bt_2004 = avg2(data_2004)\n",
    "avg_Np_2005, avg_Tp_2005, avg_Vp_2005, avg_Bgsm_x_2005, avg_Bgsm_y_2005, avg_Bgsm_z_2005, avg_Bt_2005 = avg(data_2005)\n",
    "avg_Np_2006, avg_Tp_2006, avg_Vp_2006, avg_Bgsm_x_2006, avg_Bgsm_y_2006, avg_Bgsm_z_2006, avg_Bt_2006 = avg(data_2006)\n",
    "avg_Np_2007, avg_Tp_2007, avg_Vp_2007, avg_Bgsm_x_2007, avg_Bgsm_y_2007, avg_Bgsm_z_2007, avg_Bt_2007 = avg(data_2007)\n",
    "avg_Np_2008, avg_Tp_2008, avg_Vp_2008, avg_Bgsm_x_2008, avg_Bgsm_y_2008, avg_Bgsm_z_2008, avg_Bt_2008 = avg2(data_2008)\n",
    "avg_Np_2009, avg_Tp_2009, avg_Vp_2009, avg_Bgsm_x_2009, avg_Bgsm_y_2009, avg_Bgsm_z_2009, avg_Bt_2009 = avg(data_2009)\n",
    "avg_Np_2010, avg_Tp_2010, avg_Vp_2010, avg_Bgsm_x_2010, avg_Bgsm_y_2010, avg_Bgsm_z_2010, avg_Bt_2010 = avg(data_2010)\n",
    "avg_Np_2011, avg_Tp_2011, avg_Vp_2011, avg_Bgsm_x_2011, avg_Bgsm_y_2011, avg_Bgsm_z_2011, avg_Bt_2011 = avg(data_2011)\n",
    "avg_Np_2012, avg_Tp_2012, avg_Vp_2012, avg_Bgsm_x_2012, avg_Bgsm_y_2012, avg_Bgsm_z_2012, avg_Bt_2012 = avg2(data_2012)\n",
    "avg_Np_2013, avg_Tp_2013, avg_Vp_2013, avg_Bgsm_x_2013, avg_Bgsm_y_2013, avg_Bgsm_z_2013, avg_Bt_2013 = avg(data_2013)\n",
    "\n",
    "avg_Np_prob, avg_Tp_prob, avg_Vp_prob, avg_Bgsm_x_prob, avg_Bgsm_y_prob, avg_Bgsm_z_prob, avg_Bt_prob = avg(data_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서는 데이터프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_DF2,4 : 한 셀 안에 리스트가 들어가게 하는 함수\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def mk_DF2(input_value_Np,input_value_Tp,input_value_Vp,input_value_Bgsm_x_avg,\n",
    "           input_value_Bgsm_y_avg,input_value_Bgsm_z_avg,input_value_Bt_avg,):\n",
    "\n",
    "    \n",
    "# column 부분만 따로 빼서 데이터프레임 만들기 위해 임시 행렬 만들기\n",
    "\n",
    "# 바로 밑의 빈 리스트들은 최종적으로 len(input_value_Np)개만큼 column이 있는 행렬로 만들어질 것 (그림1 참조)\n",
    "\n",
    "    arr_Np_avg=[]\n",
    "    arr_Tp_avg=[]\n",
    "    arr_Vp_avg=[]\n",
    "    arr_Bgsm_x_avg=[]\n",
    "    arr_Bgsm_y_avg=[]\n",
    "    arr_Bgsm_z_avg=[]\n",
    "    arr_Bt_avg=[]\n",
    "    \n",
    "    for j in range(0,12):\n",
    "        for i in range(0,2920): # 다른 변수들의 len이 다를리는 없다! 모두 2920개            \n",
    "            arr_Np_avg.append(input_value_Np[i][j])\n",
    "            arr_Tp_avg.append(input_value_Tp[i][j])\n",
    "            arr_Vp_avg.append(input_value_Vp[i][j])\n",
    "            arr_Bgsm_x_avg.append(input_value_Bgsm_x_avg[i][j])\n",
    "            arr_Bgsm_y_avg.append(input_value_Bgsm_y_avg[i][j])\n",
    "            arr_Bgsm_z_avg.append(input_value_Bgsm_z_avg[i][j])\n",
    "            arr_Bt_avg.append(input_value_Bt_avg[i][j])\n",
    "    \n",
    "# 이제 변수들이 채워진 arr_Np_avg, arr_Tp_avg 같은 리스트(행렬)의 각각의 열(세로줄)로 새로운 데이터프레임 만들기\n",
    "\n",
    "# 리스트들을 np를 이용해 행렬로 정의\n",
    "\n",
    "    arr_Np_avg = np.array(arr_Np_avg)\n",
    "    arr_Tp_avg = np.array(arr_Tp_avg)\n",
    "    arr_Vp_avg = np.array(arr_Vp_avg)\n",
    "    arr_Bgsm_x_avg = np.array(arr_Bgsm_x_avg)\n",
    "    arr_Bgsm_y_avg = np.array(arr_Bgsm_y_avg)\n",
    "    arr_Bgsm_z_avg = np.array(arr_Bgsm_z_avg)\n",
    "    arr_Bt_avg = np.array(arr_Bt_avg)\n",
    "    \n",
    "# 위 과정을 거치면 '그림3'과 같은 1*(2920*12) 행렬이 나옴, 이걸 '그림1'처럼 12*2920행렬로 변환해야함\n",
    "\n",
    "    arr_Np_avg = arr_Np_avg.reshape(12,2920)\n",
    "    arr_Tp_avg = arr_Tp_avg.reshape(12,2920)\n",
    "    arr_Vp_avg = arr_Vp_avg.reshape(12,2920)\n",
    "    arr_Bgsm_x_avg = arr_Bgsm_x_avg.reshape(12,2920)\n",
    "    arr_Bgsm_y_avg = arr_Bgsm_y_avg.reshape(12,2920)\n",
    "    arr_Bgsm_z_avg = arr_Bgsm_z_avg.reshape(12,2920)\n",
    "    arr_Bt_avg = arr_Bt_avg.reshape(12,2920)\n",
    "\n",
    "# arr_Np_avg처럼 '그림 1'과 같은 행렬의 모든 행에 해당하는 하나하나의 열을 뽑아 data라는 데이터프레임으로 만들기 ('그림2' 처럼)\n",
    "    \n",
    "    raw_data = OrderedDict() # 순서대로 딕셔너리 만들기\n",
    "    \n",
    "    raw_data['Np_avg'] = []\n",
    "    raw_data['Tp_avg'] = []\n",
    "    raw_data['Vp_avg'] = []\n",
    "    raw_data['Bgsm_x_avg'] = []\n",
    "    raw_data['Bgsm_y_avg'] = []\n",
    "    raw_data['Bgsm_z_avg'] = []\n",
    "    raw_data['Bt_avg'] = []\n",
    "    \n",
    "    for i in range(0,2920):\n",
    "        raw_data['Np_avg'].append(arr_Np_avg[:,i])\n",
    "        raw_data['Tp_avg'].append(arr_Tp_avg[:,i])\n",
    "        raw_data['Vp_avg'].append(arr_Vp_avg[:,i])\n",
    "        raw_data['Bgsm_x_avg'].append(arr_Bgsm_x_avg[:,i])\n",
    "        raw_data['Bgsm_y_avg'].append(arr_Bgsm_y_avg[:,i])\n",
    "        raw_data['Bgsm_z_avg'].append(arr_Bgsm_z_avg[:,i])\n",
    "        raw_data['Bt_avg'].append(arr_Bt_avg[:,i])\n",
    "   \n",
    "    data = pd.DataFrame(raw_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict # 윤년 전용\n",
    "\n",
    "def mk_DF4(input_value_Np,input_value_Tp,input_value_Vp,input_value_Bgsm_x_avg,\n",
    "           input_value_Bgsm_y_avg,input_value_Bgsm_z_avg,input_value_Bt_avg,):\n",
    "\n",
    "    \n",
    "# column 부분만 따로 빼서 데이터프레임 만들기 위해 임시 행렬 만들기\n",
    "\n",
    "# 바로 밑의 빈 리스트들은 최종적으로 len(input_value_Np)개만큼 column이 있는 행렬로 만들어질 것 (그림1 참조)\n",
    "\n",
    "    arr_Np_avg=[]\n",
    "    arr_Tp_avg=[]\n",
    "    arr_Vp_avg=[]\n",
    "    arr_Bgsm_x_avg=[]\n",
    "    arr_Bgsm_y_avg=[]\n",
    "    arr_Bgsm_z_avg=[]\n",
    "    arr_Bt_avg=[]\n",
    "    \n",
    "    for j in range(0,12):\n",
    "        for i in range(0,2928): # 다른 변수들의 len이 다를리는 없다! 모두 2920개            \n",
    "            arr_Np_avg.append(input_value_Np[i][j])\n",
    "            arr_Tp_avg.append(input_value_Tp[i][j])\n",
    "            arr_Vp_avg.append(input_value_Vp[i][j])\n",
    "            arr_Bgsm_x_avg.append(input_value_Bgsm_x_avg[i][j])\n",
    "            arr_Bgsm_y_avg.append(input_value_Bgsm_y_avg[i][j])\n",
    "            arr_Bgsm_z_avg.append(input_value_Bgsm_z_avg[i][j])\n",
    "            arr_Bt_avg.append(input_value_Bt_avg[i][j])\n",
    "        \n",
    "    raw_data = OrderedDict() # 순서대로 딕셔너리 만들기\n",
    "    \n",
    "# 이제 변수들이 채워진 arr_Np_avg, arr_Tp_avg 같은 리스트(행렬)의 각각의 열(세로줄)로 새로운 데이터프레임 만들기\n",
    "\n",
    "# 리스트들을 np를 이용해 행렬로 정의\n",
    "\n",
    "    arr_Np_avg = np.array(arr_Np_avg)\n",
    "    arr_Tp_avg = np.array(arr_Tp_avg)\n",
    "    arr_Vp_avg = np.array(arr_Vp_avg)\n",
    "    arr_Bgsm_x_avg = np.array(arr_Bgsm_x_avg)\n",
    "    arr_Bgsm_y_avg = np.array(arr_Bgsm_y_avg)\n",
    "    arr_Bgsm_z_avg = np.array(arr_Bgsm_z_avg)\n",
    "    arr_Bt_avg = np.array(arr_Bt_avg)\n",
    "\n",
    "    arr_Np_avg = arr_Np_avg.reshape(12,2928)\n",
    "    arr_Tp_avg = arr_Tp_avg.reshape(12,2928)\n",
    "    arr_Vp_avg = arr_Vp_avg.reshape(12,2928)\n",
    "    arr_Bgsm_x_avg = arr_Bgsm_x_avg.reshape(12,2928)\n",
    "    arr_Bgsm_y_avg = arr_Bgsm_y_avg.reshape(12,2928)\n",
    "    arr_Bgsm_z_avg = arr_Bgsm_z_avg.reshape(12,2928)\n",
    "    arr_Bt_avg = arr_Bt_avg.reshape(12,2928)\n",
    "\n",
    "# arr_Np_avg처럼 '그림 1'과 같은 행렬의 모든 행에 해당하는 하나하나의 열을 뽑아 data라는 데이터프레임으로 만들기 ('그림2' 처럼)\n",
    "    \n",
    "    raw_data['Np_avg'] = []\n",
    "    raw_data['Tp_avg'] = []\n",
    "    raw_data['Vp_avg'] = []\n",
    "    raw_data['Bgsm_x_avg'] = []\n",
    "    raw_data['Bgsm_y_avg'] = []\n",
    "    raw_data['Bgsm_z_avg'] = []\n",
    "    raw_data['Bt_avg'] = []\n",
    "    \n",
    "    for i in range(0,2928):\n",
    "        raw_data['Np_avg'].append(arr_Np_avg[:,i])\n",
    "        raw_data['Tp_avg'].append(arr_Tp_avg[:,i])\n",
    "        raw_data['Vp_avg'].append(arr_Vp_avg[:,i])\n",
    "        raw_data['Bgsm_x_avg'].append(arr_Bgsm_x_avg[:,i])\n",
    "        raw_data['Bgsm_y_avg'].append(arr_Bgsm_y_avg[:,i])\n",
    "        raw_data['Bgsm_z_avg'].append(arr_Bgsm_z_avg[:,i])\n",
    "        raw_data['Bt_avg'].append(arr_Bt_avg[:,i])\n",
    "   \n",
    "    data = pd.DataFrame(raw_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_1999=mk_DF2(avg_Np_1999, avg_Tp_1999, avg_Vp_1999, avg_Bgsm_x_1999, avg_Bgsm_y_1999, avg_Bgsm_z_1999, avg_Bt_1999)\n",
    "final_data_2000=mk_DF4(avg_Np_2000, avg_Tp_2000, avg_Vp_2000, avg_Bgsm_x_2000, avg_Bgsm_y_2000, avg_Bgsm_z_2000, avg_Bt_2000)\n",
    "final_data_2001=mk_DF2(avg_Np_2001, avg_Tp_2001, avg_Vp_2001, avg_Bgsm_x_2001, avg_Bgsm_y_2001, avg_Bgsm_z_2001, avg_Bt_2001)\n",
    "final_data_2002=mk_DF2(avg_Np_2002, avg_Tp_2002, avg_Vp_2002, avg_Bgsm_x_2002, avg_Bgsm_y_2002, avg_Bgsm_z_2002, avg_Bt_2002)\n",
    "final_data_2003=mk_DF2(avg_Np_2003, avg_Tp_2003, avg_Vp_2003, avg_Bgsm_x_2003, avg_Bgsm_y_2003, avg_Bgsm_z_2003, avg_Bt_2003)\n",
    "final_data_2004=mk_DF4(avg_Np_2004, avg_Tp_2004, avg_Vp_2004, avg_Bgsm_x_2004, avg_Bgsm_y_2004, avg_Bgsm_z_2004, avg_Bt_2004)\n",
    "final_data_2005=mk_DF2(avg_Np_2005, avg_Tp_2005, avg_Vp_2005, avg_Bgsm_x_2005, avg_Bgsm_y_2005, avg_Bgsm_z_2005, avg_Bt_2005)\n",
    "final_data_2006=mk_DF2(avg_Np_2006, avg_Tp_2006, avg_Vp_2006, avg_Bgsm_x_2006, avg_Bgsm_y_2006, avg_Bgsm_z_2006, avg_Bt_2006)\n",
    "final_data_2007=mk_DF2(avg_Np_2007, avg_Tp_2007, avg_Vp_2007, avg_Bgsm_x_2007, avg_Bgsm_y_2007, avg_Bgsm_z_2007, avg_Bt_2007)\n",
    "final_data_2008=mk_DF4(avg_Np_2008, avg_Tp_2008, avg_Vp_2008, avg_Bgsm_x_2008, avg_Bgsm_y_2008, avg_Bgsm_z_2008, avg_Bt_2008)\n",
    "final_data_2009=mk_DF2(avg_Np_2009, avg_Tp_2009, avg_Vp_2009, avg_Bgsm_x_2009, avg_Bgsm_y_2009, avg_Bgsm_z_2009, avg_Bt_2009)\n",
    "final_data_2010=mk_DF2(avg_Np_2010, avg_Tp_2010, avg_Vp_2010, avg_Bgsm_x_2010, avg_Bgsm_y_2010, avg_Bgsm_z_2010, avg_Bt_2010)\n",
    "final_data_2011=mk_DF2(avg_Np_2011, avg_Tp_2011, avg_Vp_2011, avg_Bgsm_x_2011, avg_Bgsm_y_2011, avg_Bgsm_z_2011, avg_Bt_2011)\n",
    "final_data_2012=mk_DF4(avg_Np_2012, avg_Tp_2012, avg_Vp_2012, avg_Bgsm_x_2012, avg_Bgsm_y_2012, avg_Bgsm_z_2012, avg_Bt_2012)\n",
    "final_data_2013=mk_DF2(avg_Np_2013, avg_Tp_2013, avg_Vp_2013, avg_Bgsm_x_2013, avg_Bgsm_y_2013, avg_Bgsm_z_2013, avg_Bt_2013)\n",
    "\n",
    "final_data_prob=mk_DF2(avg_Np_prob, avg_Tp_prob, avg_Vp_prob, avg_Bgsm_x_prob, avg_Bgsm_y_prob, avg_Bgsm_z_prob, avg_Bt_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mk_DF3 : mk_DF2,4에서 한 셀에 리스트가 들어간걸 이제 한 셀에 한값씩만 들어가도록 해주는 함수\n",
    "\n",
    "def mk_DF3(input_data): \n",
    "    \n",
    "    arr_Np_avg=[]\n",
    "    arr_Tp_avg=[]\n",
    "    arr_Vp_avg=[]\n",
    "    arr_Bgsm_x_avg=[]\n",
    "    arr_Bgsm_y_avg=[]\n",
    "    arr_Bgsm_z_avg=[]\n",
    "    arr_Bt_avg=[]\n",
    "    \n",
    "    x = len(input_data['Np_avg'].values)\n",
    "    \n",
    "    for i in range(0,x):\n",
    "        for j in range(0,12):\n",
    "            arr_Np_avg.append(input_data['Np_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Tp_avg.append(input_data['Tp_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Vp_avg.append(input_data['Vp_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Bgsm_x_avg.append(input_data['Bgsm_x_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Bgsm_y_avg.append(input_data['Bgsm_y_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Bgsm_z_avg.append(input_data['Bgsm_z_avg'].values[i][j])\n",
    "    for i in range(0, x):\n",
    "        for j in range(0,12):\n",
    "            arr_Bt_avg.append(input_data['Bt_avg'].values[i][j])\n",
    "    \n",
    "    raw_data = OrderedDict() # 순서대로 딕셔너리 만들기\n",
    "    \n",
    "    raw_data['Np_avg'] = arr_Np_avg\n",
    "    raw_data['Tp_avg'] = arr_Tp_avg\n",
    "    raw_data['Vp_avg'] = arr_Vp_avg\n",
    "    raw_data['Bgsm_x_avg'] = arr_Bgsm_x_avg\n",
    "    raw_data['Bgsm_y_avg'] = arr_Bgsm_y_avg\n",
    "    raw_data['Bgsm_z_avg'] = arr_Bgsm_z_avg\n",
    "    raw_data['Bt_avg'] = arr_Bt_avg\n",
    "    \n",
    "    data = pd.DataFrame(raw_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_1999=mk_DF3(final_data_1999)\n",
    "final_result_2000=mk_DF3(final_data_2000)\n",
    "final_result_2001=mk_DF3(final_data_2001)\n",
    "final_result_2002=mk_DF3(final_data_2002)\n",
    "final_result_2003=mk_DF3(final_data_2003)\n",
    "final_result_2004=mk_DF3(final_data_2004)\n",
    "final_result_2005=mk_DF3(final_data_2005)\n",
    "final_result_2006=mk_DF3(final_data_2006)\n",
    "final_result_2007=mk_DF3(final_data_2007)\n",
    "final_result_2008=mk_DF3(final_data_2008)\n",
    "final_result_2009=mk_DF3(final_data_2009)\n",
    "final_result_2010=mk_DF3(final_data_2010)\n",
    "final_result_2011=mk_DF3(final_data_2011)\n",
    "final_result_2012=mk_DF3(final_data_2012)\n",
    "final_result_2013=mk_DF3(final_data_2013)\n",
    "\n",
    "final_result_prob=mk_DF3(final_data_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_1999.to_csv('./final_result_1999_another.csv', index=False)\n",
    "final_result_2000.to_csv('./final_result_2000_another.csv', index=False)\n",
    "final_result_2001.to_csv('./final_result_2001_another.csv', index=False)\n",
    "final_result_2002.to_csv('./final_result_2002_another.csv', index=False)\n",
    "final_result_2003.to_csv('./final_result_2003_another.csv', index=False)\n",
    "final_result_2004.to_csv('./final_result_2004_another.csv', index=False)\n",
    "final_result_2005.to_csv('./final_result_2005_another.csv', index=False)\n",
    "final_result_2006.to_csv('./final_result_2006_another.csv', index=False)\n",
    "final_result_2007.to_csv('./final_result_2007_another.csv', index=False)\n",
    "final_result_2008.to_csv('./final_result_2008_another.csv', index=False)\n",
    "final_result_2009.to_csv('./final_result_2009_another.csv', index=False)\n",
    "final_result_2010.to_csv('./final_result_2010_another.csv', index=False)\n",
    "final_result_2011.to_csv('./final_result_2011_another.csv', index=False)\n",
    "final_result_2012.to_csv('./final_result_2012_another.csv', index=False)\n",
    "final_result_2013.to_csv('./final_result_2013_another.csv', index=False)\n",
    "\n",
    "final_result_prob.to_csv('./final_result_prob_another.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result_XXXX_another 엑셀들의 데이터를 엑셀 파일 하나에 통합시켜서 final_combine_data_another 만듦\n",
    "\n",
    "# 미싱데이터를 공백으로 놓았기에 연속적 미싱데이터가 있는 부분에선 final_result_XXXX_another에서도 공백으로 나타남\n",
    "\n",
    "# 그 데이터들을 공백으로 놓았기 때문에 final_combine_data_another도 공백이 생겼고, 그 공백을 메우기 위해 interpolation함\n",
    "\n",
    "# interpolation을 한 후 Np, Vp, Bz, Bt만 남기고 Bl도 계산하여 총 5개의 변수만 남겨서 combine_interpolation 만듦\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:\\Projects\\keras_talk\\comp_model_data\\\\'\n",
    "\n",
    "combine_data = pd.read_csv(path + 'final_combine_data_another.csv', engine='python')\n",
    "\n",
    "combine_data2 = combine_data.interpolate()\n",
    "\n",
    "combine_data2.to_csv('./combine_interpolation.csv', index=False)\n",
    "\n",
    "# 이 이후에 수동으로 5개의 변수만 남게 엑셀 파일 (combine_interpolation_an.csv) 만듦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
